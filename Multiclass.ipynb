{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm_notebook\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data_Entry_2017.csv')\n",
    "df = df[['Image Index','Finding Labels','Follow-up #','Patient ID','Patient Age','Patient Gender']]\n",
    "pathology_list = ['Cardiomegaly','Emphysema','Effusion','Hernia','Nodule','Pneumothorax','Atelectasis','Pleural_Thickening','Mass','Edema','Consolidation','Infiltration','Fibrosis','Pneumonia']\n",
    "for pathology in pathology_list :\n",
    "    df[pathology] = df['Finding Labels'].apply(lambda x: 1 if pathology in x else 0)\n",
    "df = df.set_index('Image Index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_files = os.listdir('images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = len(df.T['00000001_000.png'].iloc[5:].values.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', \n",
    "                 activation='relu', input_shape=(1024, 1024, 3), strides=(2,2)))\n",
    "model.add(MaxPooling2D(pool_size=(500,500), strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "model.compile(optimizer='sgd', loss='mse', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir_len = len(img_files)\n",
    "step_size = 10\n",
    "val_count = 300\n",
    "X_val, Y_val = [], []\n",
    "\n",
    "for img in tqdm_notebook(img_files[0:val_count]):\n",
    "    X_val.append(cv2.imread('images/'+img)/255.0)\n",
    "    Y_val.append(df.T[img].iloc[5:].values.astype(float))\n",
    "    #break\n",
    "X_val = np.array(X_val)\n",
    "Y_val = np.array(Y_val)\n",
    "tr_loss_avg, tr_acc_avg = [], []\n",
    "val_loss, val_acc = [], []\n",
    "print('Validate on:', val_count, 'Train on: ', dir_len-val_count)\n",
    "\n",
    "for epoch in range(0, 100):\n",
    "    tr_loss, tr_acc = [], []\n",
    "    for i in range(val_count, dir_len, step_size):\n",
    "        clear_output(wait=True)\n",
    "        X, Y = [], []\n",
    "        for img in img_files[i:i+step_size]:\n",
    "            X.append(cv2.imread('images/'+img)/255.0)\n",
    "            Y.append(df.T[img].iloc[5:].values.astype(float))\n",
    "            #break\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        hist = model.train_on_batch(X, Y)\n",
    "        tr_loss.append(hist[0])\n",
    "        tr_acc.append(hist[1])\n",
    "        print('progress:', format(i*100/dir_len, '.2f'), '%', \n",
    "              ', in loss:', format(hist[0], '.2f'), \n",
    "              ', in acc:', format(hist[1], '.2f'))\n",
    "        #break\n",
    "    tr_loss_avg.append(np.average(tr_loss))\n",
    "    tr_acc_avg.append(np.average(tr_acc))\n",
    "    val = model.evaluate(X_val, Y_val, verbose=0)\n",
    "    if len(val_loss)==0 or val[0]<val_loss[-1]:\n",
    "        model.save_weights(''.join(['weights/weights_cnn_epoch_', str(epoch), \n",
    "                                    '_val_loss_', format(val[0], '.2f'), \n",
    "                                    '_val_acc_', format(val[1], '.2f'),\n",
    "                                    '.hdf5']))\n",
    "    val_loss.append(val[0])\n",
    "    val_acc.append(val[1])    \n",
    "    print('epoch:',epoch, \n",
    "          ', tr loss:', format(np.average(tr_loss), '.2f'), \n",
    "          ', tr acc:', format(np.average(tr_acc), '.2f'), \n",
    "          ', val loss:', format(val[0], '.2f'),\n",
    "          ', val acc:', format(val[1], '.2f'))\n",
    "    time.sleep(0.001)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_dict = {}\n",
    "out_dict['tr_loss'] = tr_loss_avg\n",
    "out_dict['tr_acc'] = tr_acc_avg\n",
    "out_dict['val_loss'] = val_loss\n",
    "out_dict['val_acc'] = val_acc\n",
    "out_df = pd.DataFrame.from_dict(out_dict)\n",
    "out_df.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
